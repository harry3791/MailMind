오케이. 업로드가 막혀 있으면 **“파일 업로드” 대신 “Replit AI가 파일을 생성/작성”**하게 만들면 됩니다.
즉, 네가 Replit AI 채팅에 **한 번에 붙여넣으면** `app.py`, `core/retriever.py`, `pst_importer.py`, `train_model.py`, `requirements.txt` 등을 **자동으로 만들어주는 명령문**을 주면 돼요.

아래는 **학생 과제 수준**(단순, 실행 우선) + ✅ PST(무제한 임포트) + ✅ SQLite 검색 + ✅ LoRA 학습 스크립트 포함 버전입니다.

---

## Replit AI에 그대로 붙여넣을 “원샷 명령문”

> **중요:** 아래 프롬프트를 Replit AI에 붙여넣으면, Replit AI가 프로젝트 파일을 “새로 생성/덮어쓰기” 합니다.

````text
너는 Replit AI야. 지금 프로젝트에 학생 과제 수준으로 동작하는 FastAPI 앱을 만들어줘.
파일 업로드가 불가능하니, 내가 제공하는 코드로 파일을 직접 생성/수정해라.

목표:
- Run 누르면 FastAPI 서버가 뜨고 /docs에서 테스트 가능
- PST 업로드(/import_pst) → readpst로 mbox 변환 → mailbox로 전부 읽어 SQLite(emails.db)에 저장 (메일 수량 제한 없음)
- /stats 로 메일 개수 확인
- /chat 로 키워드 검색 (SQLite LIKE + 간단 점수)
- LoRA 학습은 train_model.py를 제공(학생 과제 수준)해서 SQLite에서 읽어 학습 가능

1) 아래 파일들을 생성/덮어써라:
- requirements.txt
- requirements-ml.txt
- replit.nix (가능하면)
- app.py
- pst_importer.py
- core/retriever.py
- train_model.py
- core/__init__.py (없으면 생성)

2) requirements.txt 내용:
fastapi
uvicorn[standard]
pydantic
python-multipart

3) requirements-ml.txt 내용:
torch
transformers
peft
datasets
accelerate
safetensors

4) replit.nix (가능하면):
{ pkgs }: {
  deps = [
    pkgs.pst-utils
  ];
}

※ replit.nix 적용이 안 되거나 readpst가 없을 수 있으니, app.py에서 readpst 없으면 친절히 안내하고 죽지 않게.

5) 아래 코드로 파일 작성:

[core/__init__.py]
(빈 파일)

[core/retriever.py]
```python
import json
import os
import re
import sqlite3
from typing import Any, Dict, List, Optional

def _tokens(q: str) -> List[str]:
    q = (q or "").strip()
    if not q:
        return []
    return [t for t in re.split(r"\s+", q) if t]

def _score_text(text: str, toks: List[str]) -> float:
    if not text or not toks:
        return 0.0
    low = text.lower()
    s = 0
    for t in toks:
        s += low.count(t.lower())
    return float(s)

class LocalBM25Retriever:
    """
    학생 과제 수준: 
    - data_path가 .db/.sqlite면 SQLite 검색(LIKE + 단순 score)
    - 그 외엔 JSON(리스트 or {"emails":[...]}) 로딩 후 포함검색
    """
    def __init__(self, data_path: str, attachments_root: Optional[str] = None):
        self.data_path = data_path
        self.attachments_root = attachments_root

    def _is_sqlite(self) -> bool:
        p = (self.data_path or "").lower()
        return p.endswith(".db") or p.endswith(".sqlite") or p.endswith(".sqlite3")

    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        toks = _tokens(query)
        if not toks:
            return []

        if self._is_sqlite():
            return self._search_sqlite(query, toks, top_k)
        else:
            return self._search_json(query, toks, top_k)

    def _search_sqlite(self, query: str, toks: List[str], top_k: int) -> List[Dict[str, Any]]:
        db_path = self.data_path
        if not os.path.exists(db_path):
            # DB 없으면 빈 결과
            return []

        like = f"%{query}%"
        rows: List[tuple] = []
        with sqlite3.connect(db_path) as con:
            con.row_factory = sqlite3.Row
            cur = con.cursor()
            cur.execute(
                """
                SELECT id, subject, sender, date, body
                FROM emails
                WHERE subject LIKE ? OR body LIKE ? OR sender LIKE ? OR date LIKE ?
                """,
                (like, like, like, like),
            )
            rows = cur.fetchall()

        hits: List[Dict[str, Any]] = []
        for r in rows:
            subject = (r["subject"] or "")
            body = (r["body"] or "")
            sender = (r["sender"] or "")
            date = (r["date"] or "")
            s = _score_text(subject + "\n" + body, toks)
            if s <= 0:
                continue
            hits.append({
                "mail_id": str(r["id"]),
                "subject": subject or "(no subject)",
                "score": float(s),
                "sender": sender or None,
                "date": date or None,
                "attachments": [],
                "body": body or "",
            })

        hits.sort(key=lambda x: x["score"], reverse=True)
        return hits[: max(1, int(top_k))]

    def _search_json(self, query: str, toks: List[str], top_k: int) -> List[Dict[str, Any]]:
        p = self.data_path
        if not os.path.exists(p):
            return []
        raw = json.loads(open(p, "r", encoding="utf-8").read())
        emails = raw.get("emails") if isinstance(raw, dict) else raw
        if not isinstance(emails, list):
            return []

        hits: List[Dict[str, Any]] = []
        for i, e in enumerate(emails):
            if not isinstance(e, dict):
                continue
            mail_id = str(e.get("mail_id") or e.get("id") or i)
            subject = str(e.get("subject") or "")
            body = str(e.get("body") or e.get("content") or e.get("text") or "")
            sender = e.get("sender")
            date = e.get("date")
            s = _score_text(subject + "\n" + body, toks)
            if s <= 0:
                continue
            hits.append({
                "mail_id": mail_id,
                "subject": subject or "(no subject)",
                "score": float(s),
                "sender": str(sender) if sender is not None else None,
                "date": str(date) if date is not None else None,
                "attachments": e.get("attachments") or [],
                "body": body,
            })

        hits.sort(key=lambda x: x["score"], reverse=True)
        return hits[: max(1, int(top_k))]
````

[pst_importer.py]

```python
import os
import re
import sqlite3
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, Optional

import mailbox
from email.message import Message

def _ensure_schema(db_path: str) -> None:
    with sqlite3.connect(db_path) as con:
        cur = con.cursor()
        cur.execute("""
        CREATE TABLE IF NOT EXISTS emails (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            subject TEXT,
            sender TEXT,
            date TEXT,
            body TEXT,
            importance TEXT,
            label TEXT
        )
        """)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS attachments (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            email_id INTEGER,
            filename TEXT,
            extracted_text TEXT
        )
        """)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS training_status (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            state TEXT,
            epoch INTEGER,
            step INTEGER,
            progress INTEGER,
            message TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
        """)
        con.commit()

def _extract_text_body(msg: Message) -> str:
    # text/plain 우선, 없으면 가능한 텍스트 최대한
    try:
        if msg.is_multipart():
            parts = []
            for part in msg.walk():
                ctype = (part.get_content_type() or "").lower()
                disp = (part.get("Content-Disposition") or "").lower()
                if "attachment" in disp:
                    continue
                if ctype == "text/plain":
                    payload = part.get_payload(decode=True)
                    charset = part.get_content_charset() or "utf-8"
                    try:
                        parts.append(payload.decode(charset, errors="replace"))
                    except Exception:
                        parts.append(payload.decode("utf-8", errors="replace"))
            if parts:
                return "\n".join(parts)
        # 단일 파트
        payload = msg.get_payload(decode=True)
        if isinstance(payload, (bytes, bytearray)):
            charset = msg.get_content_charset() or "utf-8"
            try:
                return payload.decode(charset, errors="replace")
            except Exception:
                return payload.decode("utf-8", errors="replace")
        if isinstance(payload, str):
            return payload
    except Exception:
        pass
    return ""

def import_pst_to_sqlite(pst_path: str, db_path: str) -> Dict[str, object]:
    _ensure_schema(db_path)

    # readpst 존재 확인
    try:
        subprocess.run(["readpst", "-V"], capture_output=True, text=True, check=False)
    except FileNotFoundError:
        raise RuntimeError("readpst not found. Install pst-utils (readpst) in Replit environment.")

    export_dir = Path(tempfile.mkdtemp(prefix="pst_export_"))
    pst_path = str(Path(pst_path).resolve())

    # PST -> mbox export
    cmd = ["readpst", "-o", str(export_dir), "-M", "-u", "-w", pst_path]
    p = subprocess.run(cmd, capture_output=True, text=True)
    if p.returncode != 0:
        raise RuntimeError(f"readpst failed: {p.stderr[:1000]}")

    # mbox 파일 찾기
    mbox_files = []
    for path in export_dir.rglob("*"):
        if path.is_file() and path.suffix.lower() in [".mbox", ".mbx", ""]:
            # readpst가 확장자 없이 mbox를 만들기도 해서, 크기 기반 필터를 약하게 적용
            if path.stat().st_size > 0:
                mbox_files.append(path)

    inserted = 0
    with sqlite3.connect(db_path) as con:
        cur = con.cursor()
        for mbox_path in mbox_files:
            try:
                mbox = mailbox.mbox(str(mbox_path))
            except Exception:
                continue

            for msg in mbox:
                subject = (msg.get("subject") or "").strip()
                sender = (msg.get("from") or "").strip()
                date = (msg.get("date") or "").strip()
                body = _extract_text_body(msg)
                # 너무 길면 DB/학습 부담 줄이기 위해 자르기(수량 제한은 없음)
                if body and len(body) > 20000:
                    body = body[:20000]

                cur.execute(
                    "INSERT INTO emails(subject, sender, date, body, importance, label) VALUES(?,?,?,?,?,?)",
                    (subject, sender, date, body, None, None),
                )
                inserted += 1

                if inserted % 500 == 0:
                    con.commit()

        con.commit()

    return {"inserted": inserted, "db_path": db_path, "export_dir": str(export_dir)}
```

[app.py]

```python
import os
import tempfile
from pathlib import Path
from typing import Optional, List, Dict, Any

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from core.retriever import LocalBM25Retriever

DEFAULT_DB = "./emails.db"
DEFAULT_ATT = "./data/attachments"

DATA_PATH = os.getenv("MAIL_JSON_PATH", DEFAULT_DB)
ATT_ROOT = os.getenv("ATTACHMENTS_ROOT", DEFAULT_ATT)

app = FastAPI(
    title="Student PST Mail App",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

retriever = LocalBM25Retriever(DATA_PATH, attachments_root=ATT_ROOT)

class ChatRequest(BaseModel):
    session_id: Optional[str] = None
    message: str
    top_k: int = 10

class Citation(BaseModel):
    mail_id: str
    subject: str
    score: float
    sender: Optional[str] = None
    date: Optional[str] = None
    attachment_names: Optional[List[str]] = None

class ChatResponse(BaseModel):
    answer: str
    citations: List[Citation] = []
    debug: Optional[Dict[str, Any]] = None

@app.get("/ping")
def ping():
    return {
        "ok": True,
        "data_path": DATA_PATH,
        "attachments_root": ATT_ROOT,
        "hint": "POST /import_pst 로 PST 업로드 후, /stats 와 /chat 사용",
    }

@app.get("/stats")
def stats():
    # retriever가 sqlite면 count 조회
    import sqlite3
    p = DATA_PATH
    if not (p.lower().endswith(".db") or p.lower().endswith(".sqlite") or p.lower().endswith(".sqlite3")):
        return {"mode": "non-sqlite", "data_path": p}

    if not os.path.exists(p):
        return {"mode": "sqlite", "emails_count": 0, "db_path": p}

    with sqlite3.connect(p) as con:
        cur = con.cursor()
        try:
            cur.execute("SELECT COUNT(*) FROM emails")
            n = cur.fetchone()[0]
        except Exception:
            n = 0
    return {"mode": "sqlite", "emails_count": int(n), "db_path": p}

@app.post("/import_pst")
def import_pst(file: UploadFile = File(...), db_path: str = DEFAULT_DB):
    if not file.filename.lower().endswith(".pst"):
        raise HTTPException(status_code=400, detail="Please upload a .pst file")

    # 임시 저장
    suffix = Path(file.filename).suffix
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp_path = tmp.name
        tmp.write(file.file.read())

    # PST -> SQLite
    try:
        from pst_importer import import_pst_to_sqlite
        result = import_pst_to_sqlite(tmp_path, db_path=db_path)
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"PST import failed: {repr(e)}. If readpst not found, install pst-utils(readpst).",
        )
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass

    # retriever DB 경로 갱신(전역)
    global DATA_PATH, retriever
    DATA_PATH = db_path
    retriever = LocalBM25Retriever(DATA_PATH, attachments_root=ATT_ROOT)

    return {"ok": True, **result}

@app.post("/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    q = (req.message or "").strip()
    if not q:
        raise HTTPException(status_code=400, detail="Empty message")

    hits = retriever.search(q, top_k=req.top_k)

    citations: List[Citation] = []
    for h in hits:
        citations.append(
            Citation(
                mail_id=str(h.get("mail_id", "")),
                subject=str(h.get("subject", "")),
                score=float(h.get("score", 0.0)),
                sender=h.get("sender"),
                date=h.get("date"),
                attachment_names=None,
            )
        )

    top_subjects = "\n".join([f"- {c.subject} (score={c.score:.1f}, id={c.mail_id})" for c in citations[:10]])
    answer = (
        f"검색어: {q}\n\n"
        f"Top 결과:\n{top_subjects if top_subjects else '- (no hits)'}"
    )

    return ChatResponse(
        answer=answer,
        citations=citations,
        debug={"top_k": req.top_k, "hits_count": len(hits)},
    )
```

[train_model.py]  (학생 과제 수준 LoRA 학습 스크립트)

```python
import argparse
import sqlite3
from typing import List, Dict

def load_examples(db_path: str, limit: int = 0) -> List[Dict[str, str]]:
    with sqlite3.connect(db_path) as con:
        con.row_factory = sqlite3.Row
        cur = con.cursor()
        q = """
        SELECT e.id, e.subject, e.sender, e.date, e.body
        FROM emails e
        """
        if limit and limit > 0:
            q += " LIMIT ?"
            cur.execute(q, (limit,))
        else:
            cur.execute(q)
        rows = cur.fetchall()

    data = []
    for r in rows:
        subject = (r["subject"] or "").strip()
        sender = (r["sender"] or "").strip()
        date = (r["date"] or "").strip()
        body = (r["body"] or "").strip()
        if len(body) > 2000:
            body = body[:2000]

        prompt = (
            "너는 조선소/해양플랜트 업무 이메일을 요약/응답 생성하는 어시스턴트다.\n"
            "아래 메일을 5줄 요약하고, 필요한 다음 액션을 3개 제안해라.\n\n"
            f"[메일]\n제목: {subject}\n발신자: {sender}\n날짜: {date}\n내용: {body}\n\n"
            "[출력]\n"
        )
        data.append({"text": prompt})
    return data

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--db_path", required=True)
    ap.add_argument("--base_model", required=True)
    ap.add_argument("--output_dir", default="./lora_out")
    ap.add_argument("--epochs", type=int, default=1)
    ap.add_argument("--limit", type=int, default=0)
    ap.add_argument("--max_length", type=int, default=512)
    args = ap.parse_args()

    from datasets import Dataset
    from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling
    from peft import LoraConfig, get_peft_model

    examples = load_examples(args.db_path, limit=args.limit)
    if not examples:
        raise SystemExit("No emails found in DB. Import PST first.")

    ds = Dataset.from_list(examples)

    tok = AutoTokenizer.from_pretrained(args.base_model, use_fast=True)
    if tok.pad_token is None:
        tok.pad_token = tok.eos_token

    def tokenize(batch):
        return tok(batch["text"], truncation=True, max_length=args.max_length)

    ds_tok = ds.map(tokenize, batched=True, remove_columns=["text"])

    model = AutoModelForCausalLM.from_pretrained(args.base_model)
    lora = LoraConfig(
        r=8,
        lora_alpha=16,
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules=["q_proj", "v_proj"]  # llama 계열 기본
    )
    model = get_peft_model(model, lora)

    collator = DataCollatorForLanguageModeling(tokenizer=tok, mlm=False)

    targs = TrainingArguments(
        output_dir=args.output_dir,
        num_train_epochs=args.epochs,
        per_device_train_batch_size=1,
        gradient_accumulation_steps=4,
        learning_rate=2e-4,
        logging_steps=10,
        save_steps=200,
        save_total_limit=2,
        fp16=False,
        report_to=[],
    )

    trainer = Trainer(
        model=model,
        args=targs,
        train_dataset=ds_tok,
        data_collator=collator,
    )

    trainer.train()
    model.save_pretrained(args.output_dir)
    tok.save_pretrained(args.output_dir)
    print("✅ LoRA adapter saved to:", args.output_dir)

if __name__ == "__main__":
    main()
```

6. Run 설정:

* Replit의 Run command를 아래로 설정:
  uvicorn app:app --host 0.0.0.0 --port 3000

7. 완료 후 사용 방법:

* /docs 접속
* POST /import_pst 로 PST 업로드 → emails.db 생성/누적
* GET /stats 로 건수 확인
* POST /chat 로 검색

학습:
pip install -r requirements-ml.txt
python train_model.py --db_path emails.db --base_model <원하는 모델ID> --epochs 1 --output_dir ./lora_out

이 모든 작업을 실제로 수행해라.

```

---

## 이렇게 하면 “업로드 없이”도 학생 프로젝트를 재현할 수 있어요
- 업로드 못 해도 **Replit AI가 파일을 직접 생성**하므로 문제 없음
- PST는 **readpst(pst-utils)** 기반이라 “학생 과제 수준”에서 가장 구현이 단순
- 메일 수량 제한은 없지만, **메모리에 다 올리지 않고 SQLite에 스트리밍 저장**이라 터질 확률이 낮음

---

## 주의 2가지 (현실 체크)
1) **Replit에 `pst-utils(readpst)`가 설치가 안 될 수도 있음**  
→ 그 경우 `/import_pst`에서 “readpst not found” 에러가 뜰 거야. 이때는 replit.nix가 먹는 환경인지부터 확인해야 해.

2) **LoRA 학습은 리소스가 많이 듬**  
→ “학습 필요”는 충족하지만, Replit 무료/저사양에서는 큰 Llama가 안 돌아갈 수 있어.  
그래도 과제 수준이면 `--base_model`을 작은 모델로 바꿔서(예: 작은 instruction 모델) 실행 테스트만 해도 충분해.

---

원하면, 네 Replit 환경이 **replit.nix 적용 가능한지/불가능한지**에 따라  
- (가능) `readpst` 그대로  
- (불가능) PST를 **미리 mbox로 변환한 파일을 업로드**하는 방식(앱은 그대로)  
둘 중 하나로 “확실히 돌아가는” 쪽으로 프롬프트를 더 최적화해줄게.
```
